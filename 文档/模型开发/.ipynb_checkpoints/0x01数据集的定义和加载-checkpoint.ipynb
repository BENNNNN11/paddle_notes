{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeacc2ec",
   "metadata": {},
   "source": [
    "## 模型开发\n",
    "1. 数据集的定义和加载\n",
    "2. 数据预处理\n",
    "3. 模型组网\n",
    "4. 训练与预测验证\n",
    "5. 单机多卡训练\n",
    "6. 自定义指标\n",
    "7. 模型保存与载入\n",
    "8. 模型导出onnx协议"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644a2b2a",
   "metadata": {},
   "source": [
    "### 数据集的定义和加载\n",
    "- 框架自带数据集\n",
    "- 自定义数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72a2fa3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "print(paddle.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40928f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "视觉相关数据集： ['DatasetFolder', 'ImageFolder', 'MNIST', 'FashionMNIST', 'Flowers', 'Cifar10', 'Cifar100', 'VOC2012']\n",
      "自然语言相关数据集： ['Conll05st', 'Imdb', 'Imikolov', 'Movielens', 'UCIHousing', 'WMT14', 'WMT16', 'ViterbiDecoder', 'viterbi_decode']\n"
     ]
    }
   ],
   "source": [
    "# 框架自带数据集\n",
    "print('视觉相关数据集：', paddle.vision.datasets.__all__)\n",
    "print('自然语言相关数据集：', paddle.text.__all__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eac35836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用ToTensor将数据格式转为Tensor\n",
    "from paddle.vision.transforms import ToTensor\n",
    "# 训练数据集\n",
    "train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=ToTensor())\n",
    "# 验证数据集\n",
    "val_dataset = paddle.vision.datasets.MNIST(mode='test', transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6975c3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4144/1153231605.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 加载内置数据集\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mpaddle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'transform' is not defined"
     ]
    }
   ],
   "source": [
    "# 加载内置数据集\n",
    "train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=transform)\n",
    "val_dataset =  paddle.vision.datasets.MNIST(mode='test', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05964c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型搭建\n",
    "minist = paddle.nn.Sequential(\n",
    "    paddle.nn.Flatten(),\n",
    "    paddle.nn.Linear(784, 512),\n",
    "    paddle.nn.ReLU(),\n",
    "    paddle.nn.Dropout(0.2),\n",
    "    paddle.nn.Linear(512, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44419f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/5\n",
      "\r",
      "step  10/938 [..............................] - loss: 1.1845 - acc: 0.3844 - ETA: 14s - 16ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\lc-or\\lib\\site-packages\\paddle\\fluid\\layers\\utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "  return (isinstance(seq, collections.Sequence) and\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 938/938 [==============================] - loss: 0.1792 - acc: 0.9037 - 5ms/step          \n",
      "Epoch 2/5\n",
      "step 938/938 [==============================] - loss: 0.0836 - acc: 0.9501 - 7ms/step          \n",
      "Epoch 3/5\n",
      "step 938/938 [==============================] - loss: 0.0118 - acc: 0.9599 - 7ms/step          \n",
      "Epoch 4/5\n",
      "step 938/938 [==============================] - loss: 0.0123 - acc: 0.9646 - 7ms/step          \n",
      "Epoch 5/5\n",
      "step 938/938 [==============================] - loss: 0.1525 - acc: 0.9684 - 6ms/step          \n"
     ]
    }
   ],
   "source": [
    "# 生成模型对象\n",
    "model = paddle.Model(minist)\n",
    "# 模型训练相关配置\n",
    "model.prepare(paddle.optimizer.Adam(parameters=model.parameters()),\n",
    "              paddle.nn.CrossEntropyLoss(),\n",
    "              paddle.metric.Accuracy())\n",
    "# 开始模型训练\n",
    "model.fit(train_dataset,\n",
    "         epochs=5,\n",
    "         batch_size=64,\n",
    "         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7ef69f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.1920928e-07], 'acc': 0.974}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型评估\n",
    "model.evaluate(val_dataset, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fef19828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "视觉相关： ['DatasetFolder', 'ImageFolder', 'MNIST', 'FashionMNIST', 'Flowers', 'Cifar10', 'Cifar100', 'VOC2012']\n",
      "自然语言相关： ['Conll05st', 'Imdb', 'Imikolov', 'Movielens', 'UCIHousing', 'WMT14', 'WMT16', 'ViterbiDecoder', 'viterbi_decode']\n"
     ]
    }
   ],
   "source": [
    "# 框架自带数据集\n",
    "print(\"视觉相关：\", paddle.vision.datasets.__all__)\n",
    "print(\"自然语言相关：\", paddle.text.__all__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "657b9454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用ToTensor将数据格式转为Tensor\n",
    "from paddle.vision.transforms import ToTensor\n",
    "\n",
    "# 训练数据集 \n",
    "train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=ToTensor())\n",
    "# 验证数据集\n",
    "val_dataset = paddle.vision.datasets.MNIST(mode='test', transform=ToTensor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "941d828b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============custom dataset=============\n",
      "[28, 28] [1]\n"
     ]
    }
   ],
   "source": [
    "# 自定义数据集\n",
    "import paddle\n",
    "from paddle.io import Dataset\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "BATCH_NUM = 20\n",
    "\n",
    "IMAGE_SIZE = (28, 28)\n",
    "CLASS_NUM = 10\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, num_samples):\n",
    "        super(MyDataset, self).__init__()\n",
    "        self.num_samples = num_samples\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = paddle.uniform(IMAGE_SIZE, dtype=\"float32\")\n",
    "        label = paddle.randint(0, CLASS_NUM-1, dtype=\"int\")\n",
    "        return data, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "# 测试定义的数据集\n",
    "custom_dataset = MyDataset(BATCH_SIZE * BATCH_NUM)\n",
    "print('=============custom dataset=============')\n",
    "for data, label in custom_dataset:\n",
    "    print(data.shape, label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0bf137c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 28, 28]\n",
      "[64, 1]\n"
     ]
    }
   ],
   "source": [
    "# 数据加载\n",
    "train_loader = paddle.io.DataLoader(custom_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "for batch_id, data in enumerate(train_loader()):\n",
    "    x_data = data[0]\n",
    "    y_data = data[1]\n",
    "    \n",
    "    print(x_data.shape)\n",
    "    print(y_data.shape)\n",
    "    \n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d14045b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Compose' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b141f841cddf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# 测试定义的数据集\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mcustom_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMyDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mBATCH_NUM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'=============custom dataset============='\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcustom_dataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-b141f841cddf>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, num_samples)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# 定义数据只能\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCompose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mReszie\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Compose' is not defined"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "from paddle.io import Dataset\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "BATCH_NUM = 20\n",
    "\n",
    "IMAGE_SIZE = (28, 28)\n",
    "CLASS_NUM = 10\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, num_samples):\n",
    "        super(MyDataset, self).__init__()\n",
    "        self.num_samples = num_samples\n",
    "        # 定义数据只能\n",
    "        self.transform = Compose([Reszie(size=32)])\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = paddle.uniform(IMAGE_SIZE, dtype=\"float32\")\n",
    "        label = paddle.randint(0, CLASS_NUM-1, dtype=\"int\")\n",
    "        return data, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "# 测试定义的数据集\n",
    "custom_dataset = MyDataset(BATCH_SIZE * BATCH_NUM)\n",
    "print('=============custom dataset=============')\n",
    "for data, label in custom_dataset:\n",
    "    print(data.shape, label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd5cb34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subclass 组网 \n",
    "class Mnist(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(Mnist, self).__init__()\n",
    "        \n",
    "        self.flatten = paddle.nn.Flatten()\n",
    "        self.linear_1 = paddle.nn.Linear(784, 512)\n",
    "        self.linear_2 = paddle.nn.Linear(512, 10)\n",
    "        self.relu = paddle.nn.ReLU()\n",
    "        self.dropout = paddle.nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(inputs):\n",
    "        y = self.flatten(inputs)\n",
    "        y = self.linear_1(y)\n",
    "        y = self.relu(y)\n",
    "        y = self.dropout(y)\n",
    "        y = self.linear_2(y)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "minit_2 = Mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34c5944a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      " Layer (type)       Input Shape          Output Shape         Param #    \n",
      "===========================================================================\n",
      "   Conv2D-1      [[64, 1, 28, 28]]     [64, 6, 28, 28]          60       \n",
      "    ReLU-2       [[64, 6, 28, 28]]     [64, 6, 28, 28]           0       \n",
      "  MaxPool2D-1    [[64, 6, 28, 28]]     [64, 6, 14, 14]           0       \n",
      "   Conv2D-2      [[64, 6, 14, 14]]     [64, 16, 10, 10]        2,416     \n",
      "    ReLU-3       [[64, 16, 10, 10]]    [64, 16, 10, 10]          0       \n",
      "  MaxPool2D-2    [[64, 16, 10, 10]]     [64, 16, 5, 5]           0       \n",
      "   Linear-3         [[64, 400]]           [64, 120]           48,120     \n",
      "   Linear-4         [[64, 120]]            [64, 84]           10,164     \n",
      "   Linear-5          [[64, 84]]            [64, 10]             850      \n",
      "===========================================================================\n",
      "Total params: 61,610\n",
      "Trainable params: 61,610\n",
      "Non-trainable params: 0\n",
      "---------------------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 7.03\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 7.46\n",
      "---------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_params': 61610, 'trainable_params': 61610}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet = paddle.vision.models.LeNet()\n",
    "paddle.summary(lenet, (64, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28080836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练和预测\n",
    "\n",
    "import paddle\n",
    "from paddle.vision.transforms import ToTensor\n",
    "\n",
    "# 加载数据集\n",
    "train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=ToTensor())\n",
    "test_dataset = paddle.vision.datasets.MNIST(mode='test', transform=ToTensor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "596be9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过paddle.Model训练与预测\n",
    "mnist = paddle.nn.Sequential(\n",
    "    paddle.nn.Flatten(1, -1), \n",
    "    paddle.nn.Linear(784, 512),\n",
    "    paddle.nn.ReLU(),\n",
    "    paddle.nn.Dropout(0.2),\n",
    "    paddle.nn.Linear(512, 10)\n",
    ")\n",
    "\n",
    "model = paddle.Model(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e289be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/5\n",
      "step 938/938 [==============================] - loss: 0.0497 - acc: 0.9852 - 14ms/step          \n",
      "Epoch 2/5\n",
      "step 938/938 [==============================] - loss: 0.0274 - acc: 0.9890 - 15ms/step          \n",
      "Epoch 3/5\n",
      "step 938/938 [==============================] - loss: 0.0047 - acc: 0.9908 - 15ms/step          \n",
      "Epoch 4/5\n",
      "step 938/938 [==============================] - loss: 0.0025 - acc: 0.9925 - 15ms/step          \n",
      "Epoch 5/5\n",
      "step 938/938 [==============================] - loss: 0.0082 - acc: 0.9925 - 13ms/step          \n"
     ]
    }
   ],
   "source": [
    "# 模型训练相关配置\n",
    "model.prepare(optimizer=paddle.optimizer.Adam(parameters=model.parameters()),\n",
    "              loss=paddle.nn.CrossEntropyLoss(),\n",
    "              metrics=paddle.metric.Accuracy())\n",
    "# 启动模型训练，指定训练集数据，设置训练轮次，设置批次大小，设置日志格式\n",
    "model.fit(train_dataset, epochs=5, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c245c080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型评估\n",
    "eval_result = model.evaluate(test_dataset, verbose=1)\n",
    "# 模型预测\n",
    "test_result = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fb0824d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch_id: 900, loss is: [0.10291342], acc is: [0.984375]\n",
      "epoch: 1, batch_id: 900, loss is: [0.18386081], acc is: [0.96875]\n",
      "epoch: 2, batch_id: 900, loss is: [0.06063517], acc is: [1.]\n",
      "epoch: 3, batch_id: 900, loss is: [0.09296639], acc is: [0.984375]\n",
      "epoch: 4, batch_id: 900, loss is: [0.0887026], acc is: [0.984375]\n"
     ]
    }
   ],
   "source": [
    "# 定义网络结构( 采用SubClass 组网 )\n",
    "class Mnist(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(Mnist, self).__init__()\n",
    "        self.flatten = paddle.nn.Flatten()\n",
    "        self.linear_1 = paddle.nn.Linear(784, 512)\n",
    "        self.linear_2 = paddle.nn.Linear(512, 10)\n",
    "        self.relu = paddle.nn.ReLU()\n",
    "        self.dropout = paddle.nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        y = self.flatten(inputs)\n",
    "        y = self.linear_1(y)\n",
    "        y = self.relu(y)\n",
    "        y = self.dropout(y)\n",
    "        y = self.linear_2(y)\n",
    "        return y\n",
    "\n",
    "# 用DataLoader实现数据加载\n",
    "train_loader = paddle.io.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "mnist = Mnist()\n",
    "mnist.train()\n",
    "\n",
    "epochs = 5 \n",
    "optim = paddle.optimizer.Adam(parameters=mnist.parameters())\n",
    "loss_fn = paddle.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_id, data in enumerate(train_loader()):\n",
    "        x_data = data[0]\n",
    "        y_data = data[1]\n",
    "        predicts = mnist(x_data)\n",
    "        \n",
    "        loss = loss_fn(predicts, y_data)\n",
    "        acc = paddle.metric.accuracy(predicts, y_data)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        if (batch_id+1) % 900 == 0:\n",
    "            print(\"epoch: {}, batch_id: {}, loss is: {}, acc is: {}\".format(epoch, batch_id+1, loss.numpy(), acc.numpy()))\n",
    "        \n",
    "        # 更新参数\n",
    "        optim.step()\n",
    "        # 梯度清零\n",
    "        optim.clear_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d796cd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id: 30, loss is: [0.09708495], acc is: [0.984375]\n",
      "batch_id: 60, loss is: [0.2270756], acc is: [0.890625]\n",
      "batch_id: 90, loss is: [0.08073302], acc is: [0.96875]\n",
      "batch_id: 120, loss is: [0.00085613], acc is: [1.]\n",
      "batch_id: 150, loss is: [0.12361488], acc is: [0.984375]\n"
     ]
    }
   ],
   "source": [
    "# 拆解model.evaluate() \n",
    "# 加载测试数据集\n",
    "test_loader = paddle.io.DataLoader(test_dataset, batch_size=64, drop_last=True)\n",
    "loss_fn = paddle.nn.CrossEntropyLoss()\n",
    "\n",
    "mnist.eval()\n",
    "\n",
    "for batch_id, data in enumerate(test_loader()):\n",
    "\n",
    "    x_data = data[0]            # 测试数据\n",
    "    y_data = data[1]            # 测试数据标签\n",
    "    predicts = mnist(x_data)    # 预测结果\n",
    "\n",
    "    # 计算损失与精度\n",
    "    loss = loss_fn(predicts, y_data)\n",
    "    acc = paddle.metric.accuracy(predicts, y_data)\n",
    "\n",
    "    # 打印信息\n",
    "    if (batch_id+1) % 30 == 0:\n",
    "        print(\"batch_id: {}, loss is: {}, acc is: {}\".format(batch_id+1, loss.numpy(), acc.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e70fa430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict finished\n"
     ]
    }
   ],
   "source": [
    "# 拆解model.predict() \n",
    "# 加载测试数据集\n",
    "test_loader = paddle.io.DataLoader(test_dataset, batch_size=64, drop_last=True)\n",
    "\n",
    "mnist.eval()\n",
    "for batch_id, data in enumerate(test_loader()):\n",
    "    x_data = data[0]\n",
    "    predicts = mnist(x_data)\n",
    "    # 获取预测结果\n",
    "print(\"predict finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c93244d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 batch 0: loss = 2.663008689880371\n",
      "Epoch 0 batch 1: loss = 2.4648823738098145\n",
      "Epoch 0 batch 2: loss = 2.207667827606201\n",
      "Epoch 0 batch 3: loss = 2.2400383949279785\n",
      "Epoch 1 batch 0: loss = 2.2761454582214355\n",
      "Epoch 1 batch 1: loss = 2.112291097640991\n",
      "Epoch 1 batch 2: loss = 2.1526315212249756\n",
      "Epoch 1 batch 3: loss = 2.4664716720581055\n",
      "Epoch 2 batch 0: loss = 2.3070621490478516\n",
      "Epoch 2 batch 1: loss = 2.4887027740478516\n",
      "Epoch 2 batch 2: loss = 2.352799415588379\n",
      "Epoch 2 batch 3: loss = 2.1782312393188477\n",
      "Epoch 3 batch 0: loss = 2.2044787406921387\n",
      "Epoch 3 batch 1: loss = 2.2824037075042725\n",
      "Epoch 3 batch 2: loss = 2.2880008220672607\n",
      "Epoch 3 batch 3: loss = 2.3408775329589844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\paddle\\fluid\\reader.py:355: UserWarning: DataLoader with multi-process mode is not supported on MacOs and Windows currently. Please use signle-process mode with num_workers = 0 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 模型保存和载入\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.optimizer as opt\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "BATCH_NUM = 4\n",
    "EPOCH_NUM = 4\n",
    "\n",
    "IMAGE_SIZE = 784\n",
    "CLASS_NUM = 10\n",
    "\n",
    "# define a random dataset\n",
    "class RandomDataset(paddle.io.Dataset):\n",
    "    def __init__(self, num_samples):\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = np.random.random([IMAGE_SIZE]).astype('float32')\n",
    "        label = np.random.randint(0, CLASS_NUM - 1, (1, )).astype('int64')\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "class LinearNet(nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self._linear = nn.Linear(IMAGE_SIZE, CLASS_NUM)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._linear(x)\n",
    "\n",
    "def train(layer, loader, loss_fn, opt):\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "        for batch_id, (image, label) in enumerate(loader()):\n",
    "            out = layer(image)\n",
    "            loss = loss_fn(out, label)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "            print(\"Epoch {} batch {}: loss = {}\".format(\n",
    "                epoch_id, batch_id, np.mean(loss.numpy())))\n",
    "\n",
    "# create network\n",
    "layer = LinearNet()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "adam = opt.Adam(learning_rate=0.001, parameters=layer.parameters())\n",
    "\n",
    "# create data loader\n",
    "dataset = RandomDataset(BATCH_NUM * BATCH_SIZE)\n",
    "loader = paddle.io.DataLoader(dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=2)\n",
    "\n",
    "# train\n",
    "train(layer, loader, loss_fn, adam)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9703445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数保存\n",
    "# 先获取layer或者optimizer的state_dict，然后将state_dict保存至磁盘\n",
    "paddle.save(layer.state_dict(), \"linear_net.pdparams\")\n",
    "paddle.save(adam.state_dict(), \"adam.pdopt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9a5d1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数载入\n",
    "# 先从磁盘上载入保存的state_dict, \n",
    "layer_state_dict = paddle.load(\"linear_net.pdparams\")\n",
    "opt_state_dict = paddle.load(\"adam.pdopt\")\n",
    "# 然后通过set_state_dict方法配置到目标对象中\n",
    "layer.set_state_dict(layer_state_dict)\n",
    "adam.set_state_dict(opt_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b936e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 静态图模型&参数保存载入\n",
    "# 若仅需要保存/载入模型的参数，可以使用 paddle.save/load 结合Program的state_dict达成目的，\n",
    "# 此处state_dict与动态图state_dict概念类似，dict的key为参数名，value为参数真实的值。\n",
    "# 若想保存整个模型，需要使用``paddle.save``将Program和state_dict都保存下来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be428de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddle.static as static\n",
    "\n",
    "paddle.enable_static()\n",
    "\n",
    "# create network\n",
    "x = paddle.static.data(name=\"x\", shape=[None, 224], dtype='float32')\n",
    "z = paddle.static.nn.fc(x, 10)\n",
    "\n",
    "place = paddle.CPUPlace()\n",
    "exe = paddle.static.Executor(place)\n",
    "exe.run(paddle.static.default_startup_program())\n",
    "prog = paddle.static.default_main_program()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23636ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "paddle.save(prog.state_dict(), \"temp/model.pdparams\")\n",
    "paddle.save(prog, \"temp/model.pdmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c5baadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prog = paddle.load(\"temp/model.pdmodel\")\n",
    "state_dict = paddle.load(\"temp/model.pdparams\")\n",
    "prog.set_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6482f9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 batch 0: loss = 2.6080944538116455\n",
      "Epoch 0 batch 1: loss = 2.672117233276367\n",
      "Epoch 0 batch 2: loss = 2.44746732711792\n",
      "Epoch 0 batch 3: loss = 2.499880075454712\n",
      "Epoch 1 batch 0: loss = 2.6856260299682617\n",
      "Epoch 1 batch 1: loss = 2.3392677307128906\n",
      "Epoch 1 batch 2: loss = 2.637976884841919\n",
      "Epoch 1 batch 3: loss = 2.3775482177734375\n",
      "Epoch 2 batch 0: loss = 2.5198330879211426\n",
      "Epoch 2 batch 1: loss = 2.394972562789917\n",
      "Epoch 2 batch 2: loss = 2.320967674255371\n",
      "Epoch 2 batch 3: loss = 2.496098756790161\n",
      "Epoch 3 batch 0: loss = 2.491642475128174\n",
      "Epoch 3 batch 1: loss = 2.539656162261963\n",
      "Epoch 3 batch 2: loss = 2.276379108428955\n",
      "Epoch 3 batch 3: loss = 2.206451416015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\lc-or\\lib\\site-packages\\paddle\\fluid\\layers\\utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "  return (isinstance(seq, collections.Sequence) and\n"
     ]
    }
   ],
   "source": [
    "# 训练部署场景的模型&参数保存载入\n",
    "# 动转静训练相比直接使用动态图训练具有更好的执行性能，\n",
    "# 训练完成后，直接将目标Layer传入 paddle.jit.save 保存即可\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.optimizer as opt\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "BATCH_NUM = 4\n",
    "EPOCH_NUM = 4\n",
    "\n",
    "IMAGE_SIZE = 784\n",
    "CLASS_NUM = 10\n",
    "\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.optimizer as opt\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "BATCH_NUM = 4\n",
    "EPOCH_NUM = 4\n",
    "\n",
    "IMAGE_SIZE = 784\n",
    "CLASS_NUM = 10\n",
    "\n",
    "paddle.disable_static()\n",
    "\n",
    "# define a random dataset\n",
    "class RandomDataset(paddle.io.Dataset):\n",
    "    def __init__(self, num_samples):\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = np.random.random([IMAGE_SIZE]).astype('float32')\n",
    "        label = np.random.randint(0, CLASS_NUM - 1, (1, )).astype('int64')\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "class LinearNet(nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self._linear = nn.Linear(IMAGE_SIZE, CLASS_NUM)\n",
    "\n",
    "    @paddle.jit.to_static\n",
    "    def forward(self, x):\n",
    "        return self._linear(x)\n",
    "\n",
    "def train(layer, loader, loss_fn, opt):\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "        for batch_id, (image, label) in enumerate(loader()):\n",
    "            out = layer(image)\n",
    "            loss = loss_fn(out, label)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "            print(\"Epoch {} batch {}: loss = {}\".format(\n",
    "                epoch_id, batch_id, np.mean(loss.numpy())))\n",
    "\n",
    "# create network\n",
    "layer = LinearNet()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "adam = opt.Adam(learning_rate=0.001, parameters=layer.parameters())\n",
    "\n",
    "# create data loader\n",
    "dataset = RandomDataset(BATCH_NUM * BATCH_SIZE)\n",
    "loader = paddle.io.DataLoader(dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=2)\n",
    "\n",
    "# train\n",
    "train(layer, loader, loss_fn, adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8819c3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "path = \"example.model/linear\"\n",
    "paddle.jit.save(layer, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecf466c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过动转静训练后保存模型&参数，有以下三项注意点：\n",
    "# 1. Layer对象的forward方法需要经由 paddle.jit.to_static 装饰\n",
    "#    若最终需要生成的描述模型的Program支持动态输入，可以同时指明模型的 InputSepc\n",
    "\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "from paddle.static import InputSpec\n",
    "\n",
    "IMAGE_SIZE = 784\n",
    "CLASS_NUM = 10\n",
    "\n",
    "class LinearNet(nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self._linear = nn.Linear(IMAGE_SIZE, CLASS_NUM)\n",
    "\n",
    "    @paddle.jit.to_static(input_spec=[InputSpec(shape=[None, 784], dtype='float32')])\n",
    "    def forward(self, x):\n",
    "        return self._linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f96fffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 请确保Layer.forward方法中仅实现预测功能，避免将训练所需的loss计算逻辑写入forward方法\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "\n",
    "IMAGE_SIZE = 784\n",
    "CLASS_NUM = 10\n",
    "\n",
    "class LinearNet(nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self._linear = nn.Linear(IMAGE_SIZE, CLASS_NUM)\n",
    "\n",
    "    @paddle.jit.to_static\n",
    "    def forward(self, x):\n",
    "        return self._linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21525322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 如果你需要保存多个方法，需要用 paddle.jit.to_static 装饰每一个需要被保存的方法\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "from paddle.static import InputSpec\n",
    "\n",
    "IMAGE_SIZE = 784\n",
    "CLASS_NUM = 10\n",
    "\n",
    "class LinearNet(nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self._linear = nn.Linear(IMAGE_SIZE, CLASS_NUM)\n",
    "        self._linear_2 = nn.Linear(IMAGE_SIZE, CLASS_NUM)\n",
    "\n",
    "    @paddle.jit.to_static(input_spec=[InputSpec(shape=[None, IMAGE_SIZE], dtype='float32')])\n",
    "    def forward(self, x):\n",
    "        return self._linear(x)\n",
    "\n",
    "    @paddle.jit.to_static(input_spec=[InputSpec(shape=[None, IMAGE_SIZE], dtype='float32')])\n",
    "    def another_forward(self, x):\n",
    "        return self._linear_2(x)\n",
    "\n",
    "inps = paddle.randn([1, IMAGE_SIZE])\n",
    "layer = LinearNet()\n",
    "before_0 = layer.another_forward(inps)\n",
    "before_1 = layer(inps)\n",
    "# save and load\n",
    "path = \"example.model/linear\"\n",
    "paddle.jit.save(layer, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe01dafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 batch 0: loss = 2.815290689468384\n",
      "Epoch 0 batch 1: loss = 2.645752429962158\n",
      "Epoch 0 batch 2: loss = 2.2527916431427\n",
      "Epoch 0 batch 3: loss = 2.3037190437316895\n",
      "Epoch 1 batch 0: loss = 2.1823887825012207\n",
      "Epoch 1 batch 1: loss = 2.3726422786712646\n",
      "Epoch 1 batch 2: loss = 2.155494213104248\n",
      "Epoch 1 batch 3: loss = 2.645132541656494\n",
      "Epoch 2 batch 0: loss = 2.6731338500976562\n",
      "Epoch 2 batch 1: loss = 2.3847076892852783\n",
      "Epoch 2 batch 2: loss = 2.3957250118255615\n",
      "Epoch 2 batch 3: loss = 2.088169574737549\n",
      "Epoch 3 batch 0: loss = 2.08514404296875\n",
      "Epoch 3 batch 1: loss = 2.4046378135681152\n",
      "Epoch 3 batch 2: loss = 2.4132843017578125\n",
      "Epoch 3 batch 3: loss = 2.578461170196533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\lc-or\\lib\\site-packages\\paddle\\fluid\\reader.py:355: UserWarning: DataLoader with multi-process mode is not supported on MacOs and Windows currently. Please use signle-process mode with num_workers = 0 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 动态图模式\n",
    "# 动态图模式相比动转静模式更加便于调试，\n",
    "# 如果你仍需要使用动态图直接训练，\n",
    "# 也可以在动态图训练完成后调用 paddle.jit.save 直接保存模型和参数。\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.optimizer as opt\n",
    "from paddle.static import InputSpec\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "BATCH_NUM = 4\n",
    "EPOCH_NUM = 4\n",
    "\n",
    "IMAGE_SIZE = 784\n",
    "CLASS_NUM = 10\n",
    "\n",
    "# define a random dataset\n",
    "class RandomDataset(paddle.io.Dataset):\n",
    "    def __init__(self, num_samples):\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = np.random.random([IMAGE_SIZE]).astype('float32')\n",
    "        label = np.random.randint(0, CLASS_NUM - 1, (1, )).astype('int64')\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "class LinearNet(nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self._linear = nn.Linear(IMAGE_SIZE, CLASS_NUM)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._linear(x)\n",
    "\n",
    "def train(layer, loader, loss_fn, opt):\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "        for batch_id, (image, label) in enumerate(loader()):\n",
    "            out = layer(image)\n",
    "            loss = loss_fn(out, label)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "            print(\"Epoch {} batch {}: loss = {}\".format(\n",
    "                epoch_id, batch_id, np.mean(loss.numpy())))\n",
    "\n",
    "# create network\n",
    "layer = LinearNet()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "adam = opt.Adam(learning_rate=0.001, parameters=layer.parameters())\n",
    "\n",
    "# create data loader\n",
    "dataset = RandomDataset(BATCH_NUM * BATCH_SIZE)\n",
    "loader = paddle.io.DataLoader(dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=2)\n",
    "\n",
    "# train\n",
    "train(layer, loader, loss_fn, adam)\n",
    "\n",
    "\n",
    "# save\n",
    "path = \"example.dy_model/linear\"\n",
    "paddle.jit.save(\n",
    "    layer=layer,\n",
    "    path=path,\n",
    "    input_spec=[InputSpec(shape=[None, 784], dtype='float32')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d4c9ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 batch 0: loss = 2.670281410217285\n",
      "Epoch 0 batch 1: loss = 2.45296049118042\n",
      "Epoch 0 batch 2: loss = 2.450043201446533\n",
      "Epoch 0 batch 3: loss = 2.212714910507202\n",
      "Epoch 1 batch 0: loss = 2.3822855949401855\n",
      "Epoch 1 batch 1: loss = 2.459423780441284\n",
      "Epoch 1 batch 2: loss = 2.630087375640869\n",
      "Epoch 1 batch 3: loss = 2.3080544471740723\n",
      "Epoch 2 batch 0: loss = 2.4624433517456055\n",
      "Epoch 2 batch 1: loss = 2.4293906688690186\n",
      "Epoch 2 batch 2: loss = 2.2825567722320557\n",
      "Epoch 2 batch 3: loss = 2.321190118789673\n",
      "Epoch 3 batch 0: loss = 2.297605514526367\n",
      "Epoch 3 batch 1: loss = 2.3585963249206543\n",
      "Epoch 3 batch 2: loss = 2.304945230484009\n",
      "Epoch 3 batch 3: loss = 2.1729393005371094\n"
     ]
    }
   ],
   "source": [
    "#  动态图模型&参数载入\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.optimizer as opt\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "BATCH_NUM = 4\n",
    "EPOCH_NUM = 4\n",
    "\n",
    "IMAGE_SIZE = 784\n",
    "CLASS_NUM = 10\n",
    "\n",
    "# load\n",
    "path = \"example.model/linear\"\n",
    "loaded_layer = paddle.jit.load(path)\n",
    "\n",
    "# inference\n",
    "loaded_layer.eval()\n",
    "x = paddle.randn([1, IMAGE_SIZE], 'float32')\n",
    "pred = loaded_layer(x)\n",
    "\n",
    "# 载入模型及参数后进行调优，示例如下（接前述示例）\n",
    "# define a random dataset\n",
    "class RandomDataset(paddle.io.Dataset):\n",
    "    def __init__(self, num_samples):\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = np.random.random([IMAGE_SIZE]).astype('float32')\n",
    "        label = np.random.randint(0, CLASS_NUM - 1, (1, )).astype('int64')\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "def train(layer, loader, loss_fn, opt):\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "        for batch_id, (image, label) in enumerate(loader()):\n",
    "            out = layer(image)\n",
    "            loss = loss_fn(out, label)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "            print(\"Epoch {} batch {}: loss = {}\".format(\n",
    "                epoch_id, batch_id, np.mean(loss.numpy())))\n",
    "\n",
    "# fine-tune\n",
    "loaded_layer.train()\n",
    "dataset = RandomDataset(BATCH_NUM * BATCH_SIZE)\n",
    "loader = paddle.io.DataLoader(dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "adam = opt.Adam(learning_rate=0.001, parameters=loaded_layer.parameters())\n",
    "train(loaded_layer, loader, loss_fn, adam)\n",
    "# save after fine-tuning\n",
    "paddle.jit.save(loaded_layer, \"fine-tune.model/linear\", input_spec=[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9246e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型导出ONNX协议\n",
    "# ONNX (Open Neural Network Exchange) 是针对机器学习所设计的开源文件格式，用于存储训练好的模型。\n",
    "# 它使得不同的人工智能框架可以采用相同格式存储模型并交互。\n",
    "# 通过ONNX格式，Paddle模型可以使用OpenVINO、ONNX Runtime等框架进行推理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "441199a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-26 10:58:54 [INFO]\tONNX model saved in onnx.save/linear_net.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\lc-or\\lib\\site-packages\\onnx\\mapping.py:27: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  int(TensorProto.STRING): np.dtype(np.object)\n",
      "D:\\anaconda\\envs\\lc-or\\lib\\site-packages\\paddle2onnx\\constant\\dtypes.py:45: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool: core.VarDesc.VarType.BOOL,\n",
      "D:\\anaconda\\envs\\lc-or\\lib\\site-packages\\paddle2onnx\\constant\\dtypes.py:46: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  core.VarDesc.VarType.FP32: np.float,\n",
      "D:\\anaconda\\envs\\lc-or\\lib\\site-packages\\paddle2onnx\\constant\\dtypes.py:51: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  core.VarDesc.VarType.BOOL: np.bool\n",
      "D:\\anaconda\\envs\\lc-or\\lib\\site-packages\\onnx\\helper.py:343: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "  is_iterable = isinstance(value, collections.Iterable)\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "from paddle import nn\n",
    "from paddle.static import InputSpec\n",
    "\n",
    "import paddle\n",
    "from paddle import nn\n",
    "from paddle.static import InputSpec\n",
    "\n",
    "class LinearNet(nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self._linear = nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._linear(x)\n",
    "\n",
    "# export to ONNX\n",
    "layer = LinearNet()\n",
    "save_path = 'onnx.save/linear_net'\n",
    "x_spec = InputSpec([None, 784], 'float32', 'x')\n",
    "paddle.onnx.export(layer, save_path, input_spec=[x_spec])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9710d61b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
