{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "315b24ee",
   "metadata": {},
   "source": [
    "## PaddleHub\n",
    "- PaddleHub是飞桨生态下的**预训练模型的管理工具**，旨在让飞桨生态下的开发者更便捷地享受到大规模预训练模型的价值。\n",
    "- 用户可以通过**PaddleHub**便捷地获取飞桨生态下的预训练模型，结合**Fine-tune API**快速完成**迁移学习到应用部署**的全流程工作，让预训练模型能更好服务于用户特定场景的应用。\n",
    "- 支持方向：文本，图像，视频，语音和工业应用等，为用户准备了大量高质量的预训练模型, 包括但不限于词法分析、情感分析、图像分类、图像分割、目标检测、关键点检测、视频分类等经典任务。支持的预训练模型可查看[PaddleHub官网](https://www.paddlepaddle.org.cn/hub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ea140a",
   "metadata": {},
   "source": [
    "### 前置条件\n",
    "- 安装Python: Linux/Mac 3.5或3.5以上，Windows 3.6或3.6以上\n",
    "- 安装飞桨2.2版本\n",
    "- 安装PaddleHub 2.0或以上版本  \n",
    "`$ pip install paddlenlp -U`  \n",
    "`$ pip install paddlehub==2.1.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db597b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\lc-or\\lib\\site-packages\\paddlenlp\\transformers\\funnel\\modeling.py:30: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "  from collections import Iterable\n"
     ]
    }
   ],
   "source": [
    "import paddlehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d160623",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-03-08 10:35:04,158] [    INFO]\u001b[0m - Request Hub-Server successfully.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用PaddleHub下载数据集、预训练模型等，要求机器可以访问外网。\n",
    "# 可以使用server_check()检查本地与远端PaddleHub-Server的连接状态\n",
    "paddlehub.server_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1505ffdd",
   "metadata": {},
   "source": [
    "### 下载预训练模型\n",
    "- 在官网上选择模型，查看模型概述和所用的数据集，选择模型版本并下载模型  \n",
    "    - `$ hub install chinese_ocr_db_crnn_server==1.1.2`  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdaed3b",
   "metadata": {},
   "source": [
    "\n",
    "### 使用命令行实现快速推理\n",
    "- `$ hub run chinese_ocr_db_crnn_server --input_path \"/PATH/TO/IMAGE\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdb2cf4",
   "metadata": {},
   "source": [
    "### 使用预训练模型进行迁移学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddde071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 选择并加载预训练模型\n",
    "import paddlehub as hub\n",
    "model = hub.Model(name=\"ernie_tiny\", \n",
    "                  version='2.0.1', \n",
    "                  task='seq_cls', # fine-tune任务，此处为seq_cls, 表示文本分类 \n",
    "                  num_class=2) # 当前文本分类任务的类别数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da005471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 准备数据集并读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b1b80e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20356/1935889426.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 选择PaddleHub提供的数据集ChnSentiCorp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# 自动从网络下载数据集并解压到用户目录下$HUB_HOME/.paddlehub/dataset目录\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m train_dataset = hub.datasets.ChnSentiCorp(\n\u001b[0m\u001b[0;32m      4\u001b[0m     tokenizer=model.get_tokenizer(), max_seq_len=128, mode='train')\n\u001b[0;32m      5\u001b[0m dev_dataset = hub.datasets.ChnSentiCorp(\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hub' is not defined"
     ]
    }
   ],
   "source": [
    "# （1）选择PaddleHub提供的数据集ChnSentiCorp\n",
    "# 自动从网络下载数据集并解压到用户目录下$HUB_HOME/.paddlehub/dataset目录\n",
    "train_dataset = hub.datasets.ChnSentiCorp(\n",
    "    tokenizer=model.get_tokenizer(), max_seq_len=128, mode='train')\n",
    "dev_dataset = hub.datasets.ChnSentiCorp(\n",
    "    tokenizer=model.get_tokenizer(), max_seq_len=128, mode='dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ec005f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) 自定义数据集, 格式如下：\n",
    "# ├──data: 数据目录\n",
    "#    ├── train.txt: 训练集数据\n",
    "#    ├── dev.txt: 验证集数据\n",
    "#    └── test.txt: 测试集数据\n",
    "# 编码格式建议为utf8格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f4c714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载自定义数据集。需要继承基类TextClassificationDataset\n",
    "from paddlehub.datasets.base_nlp_dataset import TextClassificationDataset\n",
    "\n",
    "class SeqClsDataset(TextClassificationDataset):\n",
    "    # 数据集存放目录\n",
    "    base_path = '/path/to/dataset'\n",
    "    # 数据集的标签列表\n",
    "    label_list=['体育', '科技', '社会', '娱乐', '股票', '房产', '教育', '时政', '财经', '星座', '游戏', '家居', '彩票', '时尚']\n",
    "    \n",
    "    def __init__(self, tokenizer, max_seq_len: int = 128, mode: str = 'train'):\n",
    "        if mode == 'train':\n",
    "            data_file = 'train.txt'\n",
    "        elif mode == 'test':\n",
    "            data_file = 'test.txt'\n",
    "        else:\n",
    "            data_file = 'dev.txt'\n",
    "        super().__init__(\n",
    "            base_path=self.base_path,\n",
    "            tokenizer=tokenizer,\n",
    "            max_seq_len=max_seq_len,\n",
    "            mode=mode,\n",
    "            data_file=data_file,\n",
    "            label_list=self.label_list,\n",
    "            is_file_with_header=True)\n",
    "\n",
    "        \n",
    "# 选择所需要的模型，获取对应的tokenizer\n",
    "import paddlehub as hub\n",
    "model = model = hub.Module(name='ernie_tiny', task='seq-cls', num_classes=len(SeqClsDataset.label_list))\n",
    "tokenizer = model.get_tokenizer()\n",
    "\n",
    "# 实例化训练集\n",
    "train_dataset = SeqClsDataset(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a05ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义optimizer和trainer\n",
    "import paddle\n",
    "\n",
    "optimizer = paddle.optimizer.Adam(learning_rate=5e-5, parameters=model.parameters())\n",
    "trainer = hub.Trainer(model, optimizer, checkpoint_dir='test_ernie_text_cls', use_gpu=True)\n",
    "\n",
    "trainer.train(train_dataset, epochs=3, batch_size=32, eval_dataset=dev_dataset, save_interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1538c185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测, 当完成Fine-tune后，Fine-tune过程在验证集上表现最优的模型会被保存在${CHECKPOINT_DIR}/best_model目录下\n",
    "\n",
    "import paddlehub as hub\n",
    "\n",
    "data = [\n",
    "    ['这个宾馆比较陈旧了，特价的房间也很一般。总体来说一般'],\n",
    "    ['怀着十分激动的心情放映，可是看着看着发现，在放映完毕后，出现一集米老鼠的动画片'],\n",
    "    ['作为老的四星酒店，房间依然很整洁，相当不错。机场接机服务很好，可以在车上办理入住手续，节省时间。'],\n",
    "]\n",
    "label_map = {0: 'negative', 1: 'positive'}\n",
    "\n",
    "model = hub.Module(\n",
    "    name='ernie_tiny',\n",
    "    version='2.0.1',\n",
    "    task='seq-cls',\n",
    "    load_checkpoint='./test_ernie_text_cls/best_model/model.pdparams',\n",
    "    label_map=label_map)\n",
    "\n",
    "results = model.predict(data, max_seq_len=50, batch_size=1, use_gpu=False)\n",
    "\n",
    "for idx, text in enumerate(data):\n",
    "    print('Data: {} \\t Lable: {}'.format(text[0], results[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc70e81f",
   "metadata": {},
   "source": [
    "### PaddleHub Serving一键服务部署工具\n",
    "- PaddleHub Serving是基于PaddleHub的一键模型服务部署工具，能够通过简单的Hub命令行工具轻松启动一个模型预测在线服务，前端通过Flask和Gunicorn完成网络请求的处理，后端直接调用PaddleHub预测接口，同时支持使用多进程方式利用多核提高并发能力，保证预测服务的性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc1a0a9",
   "metadata": {},
   "source": [
    "**启动服务端部署**\n",
    "- 命令启动\n",
    "```shell\n",
    "hub serving start --modules Module1==Version1 Module2==Version2 ... \\\n",
    "              --port XXXX \\\n",
    "              --use_gpu \\\n",
    "              --use_multiprocess \\\n",
    "              --workers \\\n",
    "              --gpu \\\n",
    "```\n",
    "- 配置文件启动\n",
    "    - 启动命令：\n",
    "        - `hub serving start --config config.json`\n",
    "    - config.json格式如下\n",
    "    ```json\n",
    "    {\n",
    "      \"modules_info\": {\n",
    "        \"yolov3_darknet53_coco2017\": {\n",
    "          \"init_args\": {\n",
    "            \"version\": \"1.0.0\"\n",
    "          },\n",
    "          \"predict_args\": {\n",
    "            \"batch_size\": 1,\n",
    "            \"use_gpu\": false\n",
    "          }\n",
    "        },\n",
    "        \"lac\": {\n",
    "          \"init_args\": {\n",
    "            \"version\": \"1.1.0\"\n",
    "          },\n",
    "          \"predict_args\": {\n",
    "            \"batch_size\": 1,\n",
    "            \"use_gpu\": false\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"port\": 8866,\n",
    "      \"use_multiprocess\": false,\n",
    "      \"workers\": 2,\n",
    "      \"gpu\": \"0,1,2\"\n",
    "    }\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d177787b",
   "metadata": {},
   "source": [
    "**访问服务端**\n",
    "- 在使用PaddleHub Serving部署服务端的模型预测服务后，就可以在客户端访问预测接口以获取结果了，接口url格式为：\n",
    "    - `http://127.0.0.1:8866/predict/<MODULE>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a269530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 客户端代码\n",
    "# coding: utf8\n",
    "import requests\n",
    "import json\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 指定用于预测的文本并生成字典{\"text\": [text_1, text_2, ... ]}\n",
    "    text = [\"今天是个好日子\", \"天气预报说今天要下雨\"]\n",
    "    # 以key的方式指定text传入预测方法的时的参数，此例中为\"data\"\n",
    "    # 对应本地部署，则为lac.analysis_lexical(data=text, batch_size=1)\n",
    "    data = {\"texts\": text, \"batch_size\": 1}\n",
    "    # 指定预测方法为lac并发送post请求，content-type类型应指定json方式\n",
    "    url = \"http://127.0.0.1:8866/predict/lac\"\n",
    "    # 指定post请求的headers为application/json方式\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    r = requests.post(url=url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "    # 打印预测结果\n",
    "    print(json.dumps(r.json(), indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8bc53e",
   "metadata": {},
   "source": [
    "**停止serving服务**\n",
    "- `$ hub serving stop --port XXXX`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da21a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
